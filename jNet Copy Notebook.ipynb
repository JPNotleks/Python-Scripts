{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(\"--available commands--\")? (piGraph.py, line 21)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\John\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3325\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-a64e95d60abc>\"\u001b[1;36m, line \u001b[1;32m7\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    import piGraph\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\John\\Documents\\GitHub\\Python Scripts\\piGraph.py\"\u001b[1;36m, line \u001b[1;32m21\u001b[0m\n\u001b[1;33m    print \"--available commands--\"\u001b[0m\n\u001b[1;37m                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(\"--available commands--\")?\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "import random\n",
    "import math\n",
    "from graphics import *\n",
    "from PIL import Image\n",
    "import piGraph\n",
    "import json, codecs\n",
    "\n",
    "def s(x,deriv):\n",
    "    y=np.piecewise(x,[x==0,x!=0],[0,1/(1+math.e**(-x))])\n",
    "    if deriv==0: return y\n",
    "    else: return y*(1-y)\n",
    "sigmoid=np.vectorize(s)\n",
    "panel=GraphWin(\"jNet\",1100,750,autoflush=False)\n",
    "\n",
    "eta=0.05;maxNeurons=0;l=0;net=0;netA=0;netB=0;netW=0;l=0;maxNeurons=0;dictPos=0;gradientW=0;gradientA=0;gradientB=0;gradientD=0\n",
    "regressionData=np.zeros([30])\n",
    "historyW=0;historyB=0;historyIndices=0\n",
    "#neuronWSave=open(\"neuronWeightInitialisation\",\"w+\")\n",
    "#neuronBSave=open(\"neuronBiasInitialisation\",\"w+\")\n",
    "#netSave=open(\"netSave\",\"w+\")\n",
    "\n",
    "myData=np.zeros([30])\n",
    "for i in range(30):\n",
    "    regressionData[i]=3*math.sin(2*i)+1.5    # 3,2,1.5\n",
    "\n",
    "def neuralNet(yeet):\n",
    "    global net;global netA;global netB;global netW;global l;global maxNeurons;global dictPos;global gradientW\n",
    "    global gradientA;global gradientB;global gradientD\n",
    "    piGraph.init(0,100,0,2,25,0.2,1)\n",
    "    if yeet==0:\n",
    "        net=np.array(json.loads(codecs.open(\"netSave.json\", 'r', encoding='utf-8').read()))\n",
    "    else:\n",
    "        net=np.array(yeet)\n",
    "    maxNeurons=max(net);l=len(net)\n",
    "    dictPos=np.empty([l,maxNeurons],dtype=object)                                   #position array ([layers,neurons,contents (a,w,b)])\n",
    "    netA=np.zeros([l,maxNeurons]);netW=np.zeros([l,maxNeurons,maxNeurons]);netB=np.zeros([l,maxNeurons])\n",
    "    gradientW=np.zeros([l,maxNeurons,maxNeurons]);gradientA=np.zeros([l,maxNeurons]);gradientB=np.zeros([l,maxNeurons]);gradientD=np.zeros([l,maxNeurons])\n",
    "    if yeet==0:\n",
    "        netW=np.array(json.loads(codecs.open(\"neuronWSave.json\", 'r', encoding='utf-8').read()))\n",
    "        netB=np.array(json.loads(codecs.open(\"neuronBSave.json\", 'r', encoding='utf-8').read()))\n",
    "    else:\n",
    "        netW=np.random.randint(-100,0,size=netW.shape)/500.0;netW[0,:]=0\n",
    "        for i in range(l):\n",
    "            netW[i,:,net[i-1]:]=0\n",
    "            netW[i,net[i]:]=0\n",
    "    print(netW)\n",
    "    for i in range(l):\n",
    "        for k in range(net[i]):\n",
    "            p=Point(int(200+400/l+i*180),int(50+600*k/(net[i]-1)));dictPos[i,k]=p\n",
    "    graph()\n",
    "\n",
    "def clear():panel.delete(\"all\")\n",
    "\n",
    "def dataSetup():\n",
    "    rawData = np.genfromtxt('./optdigits.tra', delimiter=',')    #data import and slicing\n",
    "    trainSet=rawData[:,0:64]    #64 data points\n",
    "    global labels;labels=rawData[:,64]    #true values\n",
    "    values=np.zeros([1000,16])    #setup for image generation\n",
    "\n",
    "    for i in range(1000):\n",
    "        for k in range(16):\n",
    "            values[i,k]=(np.sum(trainSet[i,2*k:2*k+2])+np.sum(trainSet[i,2*k+8:2*k+10]))/4    #graphic pixel reduction 64->16\n",
    "    for k in range(64):\n",
    "        r=trainSet[1,k]*15\n",
    "        c=Circle(Point(30+(k%8)*20,290+math.floor(k/8)*20),10);c.setFill(color_rgb(r,r,r));c.draw(panel)    #graphing long set\n",
    "    global inputData;inputData=trainSet    #first entry of 64 points\n",
    "\n",
    "dataSetup()\n",
    "#neuralNet([64,10])\n",
    "\n",
    "def graph():\n",
    "    clear()\n",
    "    for i in range(1,l):\n",
    "        for k in range(net[i]):\n",
    "            for r in range(net[i-1]):\n",
    "                t=255/(1+math.e**(-3*netW[i,k,r]))\n",
    "                line=Line(dictPos[i,k],dictPos[i-1,r]);line.setFill(color_rgb(t,t,t));line.draw(panel)\n",
    "    for i in range(l):\n",
    "                        for k in range(net[i]):\n",
    "                                c=Circle(dictPos[i,k],6);c.setFill(color_rgb(netA[i,k]*255,netA[i,k]*255,netA[i,k]*255));c.draw(panel)\n",
    "    for k in range(64):\n",
    "                        r=inputData[1,k]*15\n",
    "                        c=Circle(Point(30+(k%8)*20,290+math.floor(k/8)*20),10);c.setFill(color_rgb(r,r,r));c.draw(panel)\n",
    "graph()\n",
    "\n",
    "def frame(v,graphics):\n",
    "    global netA;netA[0]=inputData[v]/16.0    #feed-forward using inputs\n",
    "    for i in range(l-1):\n",
    "        netA[i+1]=sigmoid(np.dot(netW[i+1],netA[i])+netB[i+1],0)\n",
    "    if graphics==1:\n",
    "        graph()\n",
    "    y=np.zeros([maxNeurons]);y[int(labels[v])]=1\n",
    "    cost=np.sum((netA[-1][:net[-1]]-y[:net[-1]])**2)/2\n",
    "    out=np.array([y,netA,netW,netB,cost])\n",
    "    return out\n",
    "\n",
    "def backprop(input):\n",
    "    global netA,netW,gradientA,gradientB,gradientW,gradientD\n",
    "    g=input\n",
    "    gradientD[-1]=(netA[-1]-g[0])*sigmoid(netA[-1],1)    #dC/dA for deltas\n",
    "    \n",
    "    for k in range(2,l):\n",
    "        gradientD[-k]=sigmoid(netA[1-k],1)*(np.dot(netW[-k],np.reshape(gradientD[1-k],maxNeurons)))    #sigma' (hadamard) (w*gradient.T)\n",
    "    gradientB=gradientD\n",
    "    for i in range(1,l-1):\n",
    "        for k in range(net[i]):\n",
    "            gradientW[i,k]=netA[i-1]*gradientD[i,k]\n",
    "    return [gradientW,gradientB,g[4]]\n",
    "\n",
    "def train(epoch,maxIter,batch,rate):\n",
    "    global netW,netB,historyIndices,historyW,historyB;best=0;b=float(batch)\n",
    "    print(epoch*maxIter)\n",
    "    historyW=np.expand_dims(np.zeros(netW.shape),0)\n",
    "    historyB=np.expand_dims(np.zeros(netB.shape),0)\n",
    "    historyIndices=np.full((epoch*maxIter,2),100.0)\n",
    "    for r in range(epoch):\n",
    "    #if best!=0:\n",
    "    #netW=historyW[best]\n",
    "    #netB=historyB[best]\n",
    "    #print(historyIndices[best])\n",
    "        for u in range(int(maxIter/b)):\n",
    "            g=u+r*int(maxIter/b)\n",
    "            tA=np.zeros([l,maxNeurons]);tW=np.zeros([l,maxNeurons,maxNeurons]);tB=np.zeros([l,maxNeurons]);tC=0\n",
    "            for i in range(batch):\n",
    "                p=backprop(frame(r*int(maxIter/b)+u*batch+i,1))\n",
    "                tW+=p[0]\n",
    "                tB+=p[1]\n",
    "                tC+=p[2]\n",
    "                tW=tW/b;tB=tB/b;tC=tC/b\n",
    "                print(\"cost at iteration\"+\" \"+str(g)+\" \"+str(round(tC,3)))\n",
    "                netW=netW-rate*tW;netB=netB-rate*tB\n",
    "                #historyIndices[g]=[g,tC]\n",
    "                #historyW[g]=netW;historyB[g]=netB\n",
    "                piGraph.pointPlot(g,tC,2,\"black\")\n",
    "                #best=np.argsort(historyIndices[:,1])[0]\n",
    "                #print(best)\n",
    "\n",
    "def restore(n):\n",
    "    netW=historyW[n]\n",
    "    netB=historyB[n]\n",
    "\n",
    "def regression():\n",
    "    setGraph([3,30]);graph();global netA\n",
    "    a=1.0;b=1.0;c=1.0\n",
    "    for u in range(30):\n",
    "        netA[0,0]=1.0\n",
    "        netA[0,1]=1.0\n",
    "        netA[0,2]=1.0\n",
    "        for i in range(l-1):\n",
    "            netA[i+1]=sigmoid(np.dot(netW[i+1],netA[i])+netB[i+1])\n",
    "        for i in range(30):\n",
    "            myData[i]=a*math.sin(b*i)+c\n",
    "        y=regressionData;cost=np.sum((regressionData-myData)**2)\n",
    "        b=backprop(np.array([y,netA,netW,netB,cost]),1)\n",
    "        totalGradient0=np.sum(b[0][-1,:,0])\n",
    "        totalGradient1=np.sum(b[0][-1,:,1])\n",
    "        totalGradient2=np.sum(b[0][-1,:,2])\n",
    "        netW[-1,:,0]+=-eta*totalGradient0;a+=-eta*totalGradient0\n",
    "        netW[-1,:,1]+=-eta*totalGradient1;b+=-eta*totalGradient1\n",
    "        netW[-1,:,2]+=-eta*totalGradient2;c+=-eta*totalGradient2\n",
    "\n",
    "def classify(start,i):\n",
    "    counter=0.0\n",
    "    for u in range(i):\n",
    "        g=frame(start+u,0)\n",
    "        if np.argmax(g[1][-1])==labels[start+u]:\n",
    "            print(\"correct, \"+str(np.argmax(g[1][-1])))\n",
    "            counter+=1\n",
    "        else:\n",
    "            print(\"wrong, got \"+str(np.argmax(g[1][-1]))+\" instead of \"+str(int(labels[start+u])))\n",
    "    print(\"total \"+str(100.0*counter/i))\n",
    "\n",
    "def save():\n",
    "    json.dump(netW.tolist(),codecs.open(\"neuronWSave.json\", 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=True, indent=4)\n",
    "    json.dump(netB.tolist(),codecs.open(\"neuronBSave.json\", 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=True, indent=4)\n",
    "    json.dump(net.tolist(),codecs.open(\"netSave.json\", 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
