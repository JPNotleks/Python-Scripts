{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joint work with Elias Mbarek which implements a convolutional network which takes an amino acid sequence as input and predicts whether\n",
    "#a single amino acid mutation will result in a functional protein or not. It is baffling that this works at all given the arcane biochemistry\n",
    "#underlying protein folding and the relative simplicity of a convolutional neural network.\n",
    "\n",
    "from pandas import read_csv, DataFrame\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import neighbors\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Input\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Conv1D, MaxPooling1D, Add, ZeroPadding1D\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "from keras import regularizers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "data = read_csv(\"train.csv\")\n",
    "\n",
    "sequences = data[\"Sequence\"]\n",
    "\n",
    "test_data = read_csv('test.csv')\n",
    "test_sequences = test_data[\"Sequence\"]\n",
    "\n",
    "def downsampling(X, Y, Xtest = None, Ytest = None):\n",
    "\n",
    "    pos_idx = np.where(Y == 1)[0]\n",
    "    neg_idx = np.where(Y == 0)[0]\n",
    "    tot_pos = (len(pos_idx))\n",
    "    tot_neg = (len(neg_idx))\n",
    "\n",
    "    down_idx = np.random.choice(np.arange(tot_neg), tot_pos, replace = False)\n",
    "    down_train_idx =np.concatenate((pos_idx, neg_idx[down_idx]))\n",
    "\n",
    "\n",
    "    X_down, Y_down = X[down_train_idx], Y[down_train_idx]\n",
    "\n",
    "    return X_down, Y_down\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "class Swish(Activation):\n",
    "    \n",
    "    def __init__(self, activation, **kwargs):\n",
    "        super(Swish, self).__init__(activation, **kwargs)\n",
    "        self.__name__ = 'swish'\n",
    "\n",
    "def swish (x, beta =2.5):\n",
    "    return(x*K.sigmoid(beta*x))\n",
    "\n",
    "\n",
    "get_custom_objects().update({'swish':Swish(swish)})\n",
    "tokenizer = Tokenizer(char_level =True)\n",
    "tokenizer.fit_on_texts(sequences)\n",
    "tokenizer.fit_on_texts(test_sequences)\n",
    "\t\n",
    "#print(amino_sites)\n",
    "X_test_prediction = np.array(tokenizer.texts_to_sequences(test_sequences))\n",
    "X= np.array(tokenizer.texts_to_sequences(sequences))\n",
    "Y = np.genfromtxt(\"train.csv\", delimiter =',')[1:, 1]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size =0.2, random_state = 42)\n",
    "print(y_train.shape)\n",
    "\n",
    "oversample =RandomOverSampler(sampling_strategy = 'minority')\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "X_train2, y_train2 = X_train, y_train\n",
    "X_train, y_train = downsampling(X_train, y_train)\n",
    "\n",
    "X_train, X_test, X_test_prediction, X_train2 = to_categorical(X_train), to_categorical(X_test), to_categorical(X_test_prediction), to_categorical(X_train2)\n",
    "\n",
    "dependencies = {\n",
    "    'f1_m' : f1_m\n",
    "}\n",
    "\n",
    "visible = Input(shape=(4, 21))\n",
    "conv1 = Conv1D(64, kernel_size=2, dilation_rate =2, strides=1, activation='swish')(visible) \n",
    "conv2 = Conv1D(64, kernel_size=2, dilation_rate = 1, strides=2,activation='swish')(conv1)\n",
    "#conv3 = Conv1D(16, kernel_size=1, dilation_rate =1, strides=1, activation='swish')(conv2)\n",
    "bat1 = BatchNormalization()(conv2)\n",
    "#zero1=MaxPooling1D(pool_size=)(bat1)\n",
    "zero1 = ZeroPadding1D(padding=1)(bat1)\n",
    "'''\n",
    "conv3 = Conv1D(16, kernel_size=1, dilation_rate =1, strides=1, activation='swish')(zero1) \n",
    "conv4 = Conv1D(16, kernel_size=1, dilation_rate = 1, strides=1,activation='swish')(conv3)\n",
    "bat2 = BatchNormalization()(conv4)\n",
    "pool1 = MaxPooling1D(pool_size= 1)(bat2)\n",
    "'''\n",
    "flat = Flatten()(zero1)\n",
    "hidden1 = Dense(32, activation='swish')(flat)\n",
    "\n",
    "output = Dense(1, activation='sigmoid')(hidden1)\n",
    "\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_f1_m', mode = 'max', verbose = 1, save_best_only = True)\n",
    "\n",
    "model =Model(inputs = visible, outputs = output)\n",
    "opt = SGD(lr=0.1, momentum=0.9)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics =[f1_m])\n",
    "\n",
    "#fit Keras model on dataset\n",
    "weights={0:1, 1:0.07} #performed best on model (0.047)\n",
    "model.fit(X_train, y_train, class_weight = weights, epochs = 70, batch_size = 500, validation_data = (X_test, y_test), callbacks = [mc])\n",
    "\n",
    "saved_model =load_model('best_model.h5', custom_objects = dependencies)\n",
    "\n",
    "score = saved_model.evaluate(X_test, y_test)\n",
    "print('')\n",
    "print('Test loss:', score[0])\n",
    "print('Test f1_score:', score[1])\n",
    "\n",
    "\n",
    "active = saved_model.predict(X_test_prediction)\n",
    "ones = np.where(active > 0.5)\n",
    "df = DataFrame(active)\n",
    "df.loc[:] = 0\n",
    "df.loc[ones] = 1\n",
    "df.to_csv('prediction_active_final8.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
